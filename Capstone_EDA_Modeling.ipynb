{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b6789e",
   "metadata": {},
   "source": [
    "\n",
    "# Capstone EDA → Modeling Readiness (A–G)\n",
    "This notebook performs **focused EDA** and **model‑readiness** steps to support the following capabilities:\n",
    "\n",
    "**A. Risk Tolerance Prediction (Classification)**  \n",
    "**B. Customer Segmentation (Clustering with KMeans)**  \n",
    "**C. Investment Product Recommendation (Multi‑class Classification)**  \n",
    "**D. Explainable AI (SHAP if available; otherwise permutation importance / PDP)**  \n",
    "**E. Anomaly Detection (Isolation Forest)**  \n",
    "**F. Fairness & Bias Analysis (Race / Gender / City Tier)**  \n",
    "**G. Sentiment & Satisfaction Analysis (Comment → sentiment; link to satisfaction & risk)**\n",
    "\n",
    "> Notes:  \n",
    "> • Plots use Matplotlib only (no seaborn), one figure per chart, no explicit colors.  \n",
    "> • The code is robust to missing columns by detecting them dynamically.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, math, itertools, json, textwrap, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_any_dtype\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f37b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Load ===\n",
    "DATA_PATH = \"/mnt/data/Combined_Investment_Data_100k_full.csv\"\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(\"Original shape:\", df.shape)\n",
    "\n",
    "# === Normalize column names ===\n",
    "def normalize_col(c):\n",
    "    c = str(c).strip()\n",
    "    c = re.sub(r'[%]','pct',c)\n",
    "    c = re.sub(r'[^0-9a-zA-Z_ ]','', c)\n",
    "    c = re.sub(r'\\s+',' ', c).strip().lower().replace(' ', '_')\n",
    "    return c\n",
    "\n",
    "df.columns = [normalize_col(c) for c in df.columns]\n",
    "\n",
    "# Try to coerce numeric-looking strings\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        coerced = pd.to_numeric(df[col].astype(str).str.replace(',','', regex=True), errors='coerce')\n",
    "        if coerced.notna().mean() > 0.8:\n",
    "            df[col] = coerced\n",
    "\n",
    "# Identify likely text/comment field\n",
    "text_cols_guess = [c for c in df.columns if any(k in c for k in [\"comment\",\"notes\",\"free_text\",\"review\"])]\n",
    "print(\"Detected text/comment columns:\", text_cols_guess)\n",
    "\n",
    "# Basic type splits\n",
    "num_cols = [c for c in df.columns if is_numeric_dtype(df[c])]\n",
    "cat_cols = [c for c in df.columns if (df[c].dtype == object)]\n",
    "print(\"Numeric cols:\", len(num_cols), \"| Categorical cols:\", len(cat_cols))\n",
    "\n",
    "# Missing values imputation (keep copy of original for reference)\n",
    "df_clean = df.copy()\n",
    "\n",
    "for c in num_cols:\n",
    "    df_clean[c] = df_clean[c].fillna(df_clean[c].median())\n",
    "for c in cat_cols:\n",
    "    df_clean[c] = df_clean[c].fillna(\"Unknown\")\n",
    "\n",
    "# Outlier capping via IQR\n",
    "def cap_outliers(s):\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if iqr == 0 or not np.isfinite(iqr):\n",
    "        return s\n",
    "    lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    return s.clip(lower, upper)\n",
    "\n",
    "for c in num_cols:\n",
    "    df_clean[c] = cap_outliers(df_clean[c])\n",
    "\n",
    "print(\"Cleaned shape:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick sanity plots (optional): first 4 numeric histograms and first 4 categorical bars\n",
    "plot_num = num_cols[:4]\n",
    "for c in plot_num:\n",
    "    if c in df_clean:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.hist(df_clean[c].dropna().values, bins=30)\n",
    "        plt.title(f\"Distribution of {c}\")\n",
    "        plt.xlabel(c); plt.ylabel(\"Count\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_cat = cat_cols[:4]\n",
    "for c in plot_cat:\n",
    "    if c in df_clean:\n",
    "        vc = df_clean[c].astype(str).value_counts().head(10)\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.bar(vc.index.tolist(), vc.values.tolist())\n",
    "        plt.title(f\"Top categories: {c}\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ecb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_first(patterns):\n",
    "    for p in patterns:\n",
    "        for c in df_clean.columns:\n",
    "            if p in c:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "col_risk   = find_first([\"risk_tolerance\",\"risklevel\",\"risk\"])\n",
    "col_avenue = find_first([\"which_investment_avenue\",\"mostly_invest\",\"investment_avenue\",\"which_investment\"])\n",
    "col_gender = find_first([\"gender\",\"sex\"])\n",
    "col_race   = find_first([\"race\",\"ethnicity\"])\n",
    "col_city   = find_first([\"city_tier\",\"tier\"])\n",
    "col_comment= text_cols_guess[0] if text_cols_guess else None\n",
    "col_satisf = find_first([\"satisfaction\"])\n",
    "\n",
    "print(\"Targets detected:\")\n",
    "print(\" - Risk tolerance:\", col_risk)\n",
    "print(\" - Investment avenue:\", col_avenue)\n",
    "print(\"Sensitive attrs: gender:\", col_gender, \"| race:\", col_race, \"| city tier:\", col_city)\n",
    "print(\"Comment field:\", col_comment, \"| Satisfaction:\", col_satisf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === G. Sentiment Analysis (basic) ===\n",
    "# Try to use NLTK VADER if available; else fallback to a tiny lexicon approach.\n",
    "def simple_sentiment(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return 0.0\n",
    "    text_l = text.lower()\n",
    "    pos = [\"good\",\"great\",\"excellent\",\"happy\",\"satisfied\",\"love\",\"positive\",\"benefit\",\"gain\",\"profit\"]\n",
    "    neg = [\"bad\",\"poor\",\"terrible\",\"sad\",\"angry\",\"unsatisfied\",\"hate\",\"negative\",\"loss\",\"risk\"]\n",
    "    score = sum(1 for w in pos if w in text_l) - sum(1 for w in neg if w in text_l)\n",
    "    return float(score)\n",
    "\n",
    "if col_comment:\n",
    "    df_clean[\"sentiment_score\"] = df_clean[col_comment].astype(str).map(simple_sentiment)\n",
    "    print(\"Sample sentiment scores:\", df_clean[\"sentiment_score\"].head().tolist())\n",
    "else:\n",
    "    print(\"No comment/text column found; skipping sentiment score creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bedecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === A. Risk Tolerance Prediction (Classification) ===\n",
    "results_A = {}\n",
    "if col_risk:\n",
    "    # Build X/y\n",
    "    y = df_clean[col_risk].astype(str)\n",
    "    X = df_clean.drop(columns=[col_risk])\n",
    "\n",
    "    # Split columns by type again post-clean\n",
    "    X_num = [c for c in X.columns if is_numeric_dtype(X[c])]\n",
    "    X_cat = [c for c in X.columns if X[c].dtype == object]\n",
    "\n",
    "    pre = ColumnTransformer(transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), X_num),\n",
    "        (\"cat\", Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                               (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), X_cat)\n",
    "    ])\n",
    "\n",
    "    # Use a compact yet strong baseline\n",
    "    clf = Pipeline(steps=[(\"pre\", pre),\n",
    "                          (\"model\", GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc  = accuracy_score(y_test, preds)\n",
    "    f1m  = f1_score(y_test, preds, average=\"macro\")\n",
    "    print(\"Risk Tolerance → Accuracy:\", round(acc,4), \"| Macro-F1:\", round(f1m,4))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, preds))\n",
    "\n",
    "    # Permutation importance for explainability\n",
    "    try:\n",
    "        perm = permutation_importance(clf, X_test, y_test, n_repeats=5, random_state=42, n_jobs=1)\n",
    "        importances = perm.importances_mean\n",
    "        # Retrieve feature names from ColumnTransformer\n",
    "        oh = clf.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"oh\"]\n",
    "        cat_features = oh.get_feature_names_out(X_cat).tolist() if len(X_cat) else []\n",
    "        feature_names = X_num + cat_features\n",
    "        idx = np.argsort(importances)[::-1][:20]\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.bar(range(len(idx)), importances[idx])\n",
    "        plt.xticks(range(len(idx)), [feature_names[i] for i in idx], rotation=90)\n",
    "        plt.title(\"Permutation Importance – Risk Tolerance Model (Top 20)\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Permutation importance unavailable:\", e)\n",
    "\n",
    "    results_A = {\"accuracy\": acc, \"macro_f1\": f1m}\n",
    "else:\n",
    "    print(\"No risk tolerance column detected; skipping A.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === B. Customer Segmentation (KMeans) ===\n",
    "results_B = {}\n",
    "# Use numeric features only; add engineered sentiment if exists\n",
    "cluster_df = df_clean[[c for c in df_clean.columns if is_numeric_dtype(df_clean[c])]].copy()\n",
    "cluster_df = cluster_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "if cluster_df.shape[1] >= 2 and cluster_df.shape[0] >= 50:\n",
    "    scaler = StandardScaler()\n",
    "    Xc = scaler.fit_transform(cluster_df)\n",
    "\n",
    "    # Elbow-like quick sweep of inertia for k=2..6\n",
    "    inertias = []\n",
    "    K = list(range(2,7))\n",
    "    for k in K:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        km.fit(Xc)\n",
    "        inertias.append(km.inertia_)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(K, inertias, marker='o')\n",
    "    plt.title(\"KMeans: Inertia by K (Elbow)\")\n",
    "    plt.xlabel(\"k\"); plt.ylabel(\"Inertia\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Choose k=4 by default\n",
    "    k = 4\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(Xc)\n",
    "    results_B[\"k\"] = k\n",
    "    df_clean[\"cluster_k4\"] = labels\n",
    "\n",
    "    # PCA 2D scatter\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X2 = pca.fit_transform(Xc)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for lab in sorted(set(labels)):\n",
    "        pts = X2[labels==lab]\n",
    "        plt.scatter(pts[:,0], pts[:,1], alpha=0.4, label=f\"Cluster {lab}\")\n",
    "    plt.title(\"KMeans Clusters (k=4) – PCA Projection\")\n",
    "    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Insufficient numeric features/rows for clustering; skipping B.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === C. Investment Product Recommendation (Classification) ===\n",
    "results_C = {}\n",
    "if col_avenue:\n",
    "    y = df_clean[col_avenue].astype(str)\n",
    "    X = df_clean.drop(columns=[col_avenue])\n",
    "\n",
    "    X_num = [c for c in X.columns if is_numeric_dtype(X[c])]\n",
    "    X_cat = [c for c in X.columns if X[c].dtype == object]\n",
    "\n",
    "    pre = ColumnTransformer(transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), X_num),\n",
    "        (\"cat\", Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                               (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), X_cat)\n",
    "    ])\n",
    "\n",
    "    clf = Pipeline(steps=[(\"pre\", pre),\n",
    "                          (\"model\", GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc  = accuracy_score(y_test, preds)\n",
    "    f1m  = f1_score(y_test, preds, average=\"macro\")\n",
    "    print(\"Investment Avenue → Accuracy:\", round(acc,4), \"| Macro-F1:\", round(f1m,4))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, preds))\n",
    "\n",
    "    # Permutation importance\n",
    "    try:\n",
    "        perm = permutation_importance(clf, X_test, y_test, n_repeats=5, random_state=42, n_jobs=1)\n",
    "        importances = perm.importances_mean\n",
    "        oh = clf.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"oh\"]\n",
    "        cat_features = oh.get_feature_names_out(X_cat).tolist() if len(X_cat) else []\n",
    "        feature_names = X_num + cat_features\n",
    "        idx = np.argsort(importances)[::-1][:20]\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.bar(range(len(idx)), importances[idx])\n",
    "        plt.xticks(range(len(idx)), [feature_names[i] for i in idx], rotation=90)\n",
    "        plt.title(\"Permutation Importance – Investment Avenue Model (Top 20)\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Permutation importance unavailable:\", e)\n",
    "\n",
    "    results_C = {\"accuracy\": acc, \"macro_f1\": f1m}\n",
    "else:\n",
    "    print(\"No investment avenue column detected; skipping C.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === D. Explainable AI (SHAP if available) ===\n",
    "def try_shap_global(clf, X_sample):\n",
    "    try:\n",
    "        import shap\n",
    "        explainer = shap.Explainer(clf.named_steps[\"model\"], feature_names=None)\n",
    "        # We need model-ready matrix; get from preprocessor\n",
    "        Xt = clf.named_steps[\"pre\"].transform(X_sample)\n",
    "        shap_values = explainer(Xt, check_additivity=False)\n",
    "        shap.plots.beeswarm(shap_values, show=False)\n",
    "        plt.title(\"SHAP – Global Feature Impact\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"SHAP not available or failed:\", e)\n",
    "        return False\n",
    "\n",
    "# Attempt SHAP for A and C models using holdout data if available\n",
    "# (Note: Only runs if the previous cells defined clf and X_test appropriately)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420096ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === E. Anomaly Detection (IsolationForest) ===\n",
    "anom_df = df_clean[[c for c in df_clean.columns if is_numeric_dtype(df_clean[c])]].copy()\n",
    "anom_df = anom_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "if anom_df.shape[1] >= 2:\n",
    "    iso = IsolationForest(contamination=0.02, random_state=42)\n",
    "    scores = iso.fit_predict(anom_df)\n",
    "    df_clean[\"anomaly_flag\"] = (scores == -1).astype(int)\n",
    "    print(\"Anomalies flagged:\", int(df_clean[\"anomaly_flag\"].sum()))\n",
    "    # Show a small sample\n",
    "    display_cols = ([\"anomaly_flag\"] + anom_df.columns.tolist()[:5])[:6]\n",
    "    print(df_clean[display_cols].head(10))\n",
    "else:\n",
    "    print(\"Insufficient numeric features for IsolationForest; skipping E.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6105299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === F. Fairness & Bias Analysis ===\n",
    "def group_metrics(y_true, y_pred, group):\n",
    "    # group: pandas Series of group labels aligned with y_true/y_pred\n",
    "    dfm = pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred, \"grp\": group})\n",
    "    mets = {}\n",
    "    # Accuracy by group\n",
    "    for g, sub in dfm.groupby(\"grp\"):\n",
    "        mets[g] = {\n",
    "            \"count\": len(sub),\n",
    "            \"accuracy\": accuracy_score(sub[\"y_true\"], sub[\"y_pred\"]),\n",
    "            \"positive_rate_pred\": (sub[\"y_pred\"].value_counts(normalize=True).max() \n",
    "                                   if len(sub)>0 else np.nan)\n",
    "        }\n",
    "    return pd.DataFrame(mets).T\n",
    "\n",
    "def fairness_report(y_true, y_pred, sensitive_series, title):\n",
    "    if sensitive_series is None:\n",
    "        print(f\"{title}: Sensitive attribute not found; skipping.\")\n",
    "        return\n",
    "    print(f\"\\nFairness report – {title} by {sensitive_series.name}:\")\n",
    "    rep = group_metrics(y_true, y_pred, sensitive_series.astype(str))\n",
    "    print(rep)\n",
    "    # Simple parity diffs\n",
    "    if rep.shape[0] >= 2:\n",
    "        acc_range = rep[\"accuracy\"].max() - rep[\"accuracy\"].min()\n",
    "        pos_range = rep[\"positive_rate_pred\"].max() - rep[\"positive_rate_pred\"].min()\n",
    "        print(f\"Accuracy disparity range: {acc_range:.3f} | Pred positive rate disparity range: {pos_range:.3f}\")\n",
    "\n",
    "# Apply to A and C if available\n",
    "try:\n",
    "    # For A\n",
    "    if 'preds' in globals() and col_risk:\n",
    "        fairness_report(y_test, preds, df_clean.loc[y_test.index, col_gender] if col_gender else None, \"Risk Tolerance (Gender)\")\n",
    "        fairness_report(y_test, preds, df_clean.loc[y_test.index, col_race] if col_race else None, \"Risk Tolerance (Race)\")\n",
    "        fairness_report(y_test, preds, df_clean.loc[y_test.index, col_city] if col_city else None, \"Risk Tolerance (City Tier)\")\n",
    "except Exception as e:\n",
    "    print(\"Fairness check (A) skipped/failed:\", e)\n",
    "\n",
    "try:\n",
    "    # For C: recompute y_test_C, preds_C if not in scope\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(\"Fairness check (C) skipped/failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9636f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === G. Sentiment/Satisfaction Link ===\n",
    "if \"sentiment_score\" in df_clean.columns and col_satisf:\n",
    "    # Plot satisfaction vs sentiment\n",
    "    groups = df_clean[col_satisf].astype(str).value_counts().index[:8]\n",
    "    means = []\n",
    "    for g in groups:\n",
    "        means.append(df_clean.loc[df_clean[col_satisf].astype(str)==g, \"sentiment_score\"].mean())\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.bar(list(groups), means)\n",
    "    plt.title(\"Average Sentiment Score by Satisfaction\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Avg sentiment_score\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"Sentiment or satisfaction not available; skipping plot.\")\n",
    "\n",
    "# Link sentiment to risk if available\n",
    "if \"sentiment_score\" in df_clean.columns and col_risk:\n",
    "    groups = df_clean[col_risk].astype(str).value_counts().index[:8]\n",
    "    means = []\n",
    "    for g in groups:\n",
    "        means.append(df_clean.loc[df_clean[col_risk].astype(str)==g, \"sentiment_score\"].mean())\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.bar(list(groups), means)\n",
    "    plt.title(\"Average Sentiment Score by Risk Tolerance\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Avg sentiment_score\")\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec221fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save cleaned dataset with engineered fields (clusters, anomaly flag, sentiment)\n",
    "out_path = \"/mnt/data/cleaned_with_features.csv\"\n",
    "df_clean.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
